# 2025-10-19 Devlog (Wave 1 Day 5)

## Highlights
- Replaced the Raft supervisor stub with a fully wired OpenRaft runtime that exposes the consensus RPCs over HTTP and feeds leadership changes into the shared telemetry counters.
- Added single-node coverage plus a quorum-aware three-node failover test to guard the new Raft path alongside the Postgres coordinator and documented the multi-node bring-up procedure for local operators.
- Updated the implementation log and environment guide so future contributors can bootstrap the Raft cluster and verify leadership transitions via the metrics endpoint.

## Stream Updates
### Horology Kernel (HK)
- Yesterday: Postgres-backed coordinator handled failover but Raft support was stubbed out pending OpenRaft integration.
- Today: Implemented the `RaftSupervisor` with HTTP RPC handlers, memstore-backed state, and leader tracking via `LeaderHandle`; metrics now capture Raft leadership transitions just like the Postgres coordinator.
- Risks / Blockers: Need to plumb Raft metrics into the Phase 1 harness and Prometheus dashboards to keep both coordinators observable (HK-OBS-05).
- Telemetry Links: `cargo test --manifest-path services/horology-kernel/Cargo.toml` covers the new Raft leadership and failover tests.

### Control Plane (CP)
- Yesterday: Gateway handled Postgres coordinator leadership hints only.
- Today: No code changes, but Raft supervisor now emits the same leader handle semantics the control plane consumes, unblocking future multi-coordinator awareness.
- Risks / Blockers: Surface Raft leader metadata in policy middleware once the command bus becomes cluster aware (CP-POLICY-10).
- Telemetry Links: n/a.

### Execution Mesh (EM)
- Yesterday: Harness validated JetStream + HTTP/gRPC flows against Postgres leaders.
- Today: No functional changes; next step is to extend orchestrator failover tests once Raft metrics are surfaced.
- Risks / Blockers: Leader-aware orchestrator consumers remain on backlog (EM-BUS-04).
- Telemetry Links: n/a.

### Developer Experience (DX)
- Yesterday: Local environment guide covered Postgres coordinator and simulated follower flows.
- Today: Documented multi-node Raft bring-up, including peer configuration examples and HTTP RPC details so operators can spin up multi-node clusters quickly.
- Risks / Blockers: Harness still only validates Postgres leadership; add Raft stage post-metrics plumbing (DX-TEST-08).
- Telemetry Links: `docs/devx/LOCAL_ENVIRONMENT.md` Raft section.

### Governance
- Yesterday: Leadership audit trail depended on coordinator metrics only.
- Today: Raft supervisor emits the same telemetry events so audit logs can capture leadership transitions regardless of coordinator mode.
- Risks / Blockers: Persisting Raft transitions into the audit log remains open (GOV-AUDIT-02).
- Telemetry Links: Prometheus `/metrics` with `kernel_coordinator_leadership_transitions` counters.

## Testing Summary
- ✅ command `cargo test --manifest-path services/horology-kernel/Cargo.toml`
- ✅ command `npm test -- --passWithNoTests`
- ✅ command `npm run build`
- ✅ command `node scripts/check-devlog-entry.js`

## Decisions & Follow-ups
- Decision: The HTTP-backed OpenRaft supervisor becomes the default when `KERNEL_RAFT_NODE_ID` is set, giving parity with the Postgres coordinator for leader detection (owner: HK core team, logged 2025-10-19).
- Follow-up: Extend the Phase 1 integration harness to run a quorum-capable three-node Raft cluster and assert failover metrics (owners: HK/DX pairing, due 2025-10-22).
- Follow-up: Surface Raft-specific metrics and leader metadata through the control plane policy wall once command routing is Raft-aware (owners: CP guild, due 2025-10-24).
